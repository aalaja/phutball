{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model-training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "PyTorch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sOBf9FoVO5gY"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ypbH-_VO5gZ"
      },
      "source": [
        "## Create Filesystem\n",
        "This notebook is primarily meant to be executed in Colab as a computational backend. If you want to run on your own hardware with data, you need to set `data_dir` and `ALLOW_IO`\n",
        "\n",
        "This notebook viewable directly on Colab from [https://colab.research.google.com/github/rcharan/phutball/blob/rl/pytorch-implementation/model-training.ipynb](https://colab.research.google.com/github/rcharan/phutball/blob/rl/pytorch-implementation/model-training.ipynb) (it is a mirror of github). But if it has moved branches or you are looking at a past commit, look at the [Google instructions](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb) on where to find this file.\n",
        "\n",
        "The workflow is:\n",
        " - Data stored in (my personal/private) Google Drive\n",
        " - Utilities/library files (for importing) on github, edited on local hardware and pushed to github.\n",
        " - Notebook hosted on github, edited both in Colab or locally (depending on the relative value of having a GPU attached versus being able to use regular Jupyter keyboard shortcuts/a superior interface)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RY-nqnzUzB5k",
        "outputId": "93305712-8433-4329-d16d-d1dc9f0f6198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Attempt Colab setup if on Colab\n",
        "try:\n",
        "  import google.colab\n",
        "except:\n",
        "  ALLOW_IO = False\n",
        "else:\n",
        "  # Mount Google Drive at data_dir\n",
        "  #  (for data)\n",
        "  from google.colab import drive\n",
        "  from os.path import join\n",
        "  ROOT = '/content/drive'\n",
        "  DATA = 'My Drive/phutball'\n",
        "  drive.mount(ROOT)\n",
        "  ALLOW_IO = True\n",
        "  data_dir = join(ROOT, DATA)\n",
        "  !mkdir \"{data_dir}\"     # in case we haven't created it already   \n",
        "\n",
        "  # Pull in code from github\n",
        "  %cd /content\n",
        "  github_repo = 'https://github.com/rcharan/phutball'\n",
        "  !git clone -b rl {github_repo}\n",
        "  %cd /content/phutball\n",
        "  \n",
        "  # Point python to code base\n",
        "  import sys\n",
        "  sys.path.append('/content/phutball/pytorch-implementation')\n",
        "\n",
        "  # Updater for library functions changed on local hardware and pushed to github\n",
        "  #  (circuitous, I know)\n",
        "  def update_repo():\n",
        "    !git pull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/phutball’: File exists\n",
            "/content\n",
            "Cloning into 'phutball'...\n",
            "remote: Enumerating objects: 583, done.\u001b[K\n",
            "remote: Counting objects: 100% (583/583), done.\u001b[K\n",
            "remote: Compressing objects: 100% (390/390), done.\u001b[K\n",
            "remote: Total 1965 (delta 365), reused 365 (delta 190), pack-reused 1382\u001b[K\n",
            "Receiving objects: 100% (1965/1965), 22.48 MiB | 28.14 MiB/s, done.\n",
            "Resolving deltas: 100% (1193/1193), done.\n",
            "/content/phutball\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF1C55w-O5gg"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbaorYhzwUze",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "\n",
        "# Codebase\n",
        "from lib.model_v2          import TDConway\n",
        "from lib.off_policy        import EpsilonGreedy\n",
        "from lib.optim             import AlternatingTDLambda\n",
        "\n",
        "from lib.training          import training_loop\n",
        "\n",
        "from lib.utilities         import config, lfilter\n",
        "from lib.testing_utilities import create_state, visualize_state, boards\n",
        "from lib.timer             import Timer\n",
        "\n",
        "from lib.move_selection    import get_next_move_training\n",
        "\n",
        "\n",
        "# Graphics for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "plt.ioff()\n",
        "\n",
        "# PyTorch\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOk4kKeOO5gm"
      },
      "source": [
        "## Device Management Utilities\n",
        "Setup for GPU, CPU, or (not working well/fully implemented) TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A7ETHYgbO5gm",
        "outputId": "e9750bbf-4631-40fd-c963-837719a78bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "use_tpu = False\n",
        "\n",
        "if use_tpu:\n",
        "  # This section doesn't run\n",
        "  # Install PyTorch/XLA\n",
        "  VERSION = \"nightly\" #[\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
        "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "  !python pytorch-xla-env-setup.py --version $VERSION\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "  \n",
        "  # Set the device\n",
        "  device = xm.xla_device()\n",
        "  \n",
        "  # Memory inspection\n",
        "  def print_memory_usage():\n",
        "    print('TPU memory inspection not implemented')\n",
        "  def print_max_memory_usage():\n",
        "    print('TPU memory inspection not implemented')\n",
        "  def garbage_collect():\n",
        "    gc.collect() # No TPU specific implementation yet\n",
        "    \n",
        "elif torch.cuda.is_available():\n",
        "  # Set the device\n",
        "  device = torch.device('cuda')\n",
        "  \n",
        "  # Echo GPU info\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  print(gpu_info)\n",
        "  \n",
        "  # Memory inspection and management\n",
        "  from lib.memory import (\n",
        "    print_memory_usage_cuda     as print_memory_usage,\n",
        "    print_max_memory_usage_cuda as print_max_memory_usage,\n",
        "    garbage_collect_cuda        as garbage_collect\n",
        "  )\n",
        "\n",
        "else:\n",
        "  # Set the device to CPU\n",
        "  device = torch.device('cpu')\n",
        "  \n",
        "  # Echo RAM info\n",
        "  from psutil import virtual_memory\n",
        "  from lib.memory import format_bytes\n",
        "  ram = virtual_memory().total\n",
        "  print(format_bytes(ram), 'available memory on CPU-based runtime')\n",
        "  \n",
        "  # Memory inspection and management\n",
        "  from lib.memory import (\n",
        "    print_memory_usage, \n",
        "    print_max_memory_usage,\n",
        "    garbage_collect\n",
        "  )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May 20 18:12:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KxB31wNMO5hG"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tHORM9o9TCgY",
        "colab": {}
      },
      "source": [
        "def save(fname, model):\n",
        "  state_dict = {\n",
        "      'model' : model.state_dict(),\n",
        "  }\n",
        "  torch.save(state_dict, f'{data_dir}/{fname}.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXYUZNU6qQWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fname(version, game_num):\n",
        "  return f'v{version}-{game_num}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl2pMjzH4Iex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load(version, game_num, model):\n",
        "  sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt')\n",
        "  model.load_state_dict(sd['model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cd-9BUVBJOM",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgnPBVNB4XTo",
        "colab_type": "text"
      },
      "source": [
        "## Fit one cycle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTstggDJiTjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lib.pretraining.fit_one_cycle import fit_one_cycle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y943nd1nxNnL",
        "colab_type": "code",
        "outputId": "dd2f882a-d3c4-4c62-fddb-34a187aca70e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = TDConway(config).to(device)\n",
        "data = fit_one_cycle(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6942/6942 [==============================] - 274s 40ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgvyC2ptxvsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a-xUM-4x8eM",
        "colab_type": "code",
        "outputId": "a4dedb3a-9d20-432b-fea2-c566f199e965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "df = pd.DataFrame(data, columns = ['lr', 'loss'])\n",
        "df['loss'] = df.loss.apply(lambda l : l.item())\n",
        "df = df.groupby('lr').mean().reset_index()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "sns.lineplot(x = 'lr', y='loss', data = df, ax = ax)\n",
        "ax.set_xscale('log', basex = 10)\n",
        "ax.set_yscale('log', basey = 10)\n",
        "fig"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrt0AqtH4iYO",
        "colab_type": "text"
      },
      "source": [
        "## Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_TWjyDcidf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lib.pretraining.pre_training import pre_train\n",
        "from torch.optim import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfsZxT94iaIx",
        "colab_type": "code",
        "outputId": "592d0717-0be1-44f2-f696-31df8ab3ab32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = TDConway(config).to(device)\n",
        "optimizer = SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "pre_train(model, optimizer, loops = 10000, batch_size = 300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 422s 42ms/step - loss: 0.0043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weZKL4738w78",
        "colab_type": "code",
        "outputId": "f0cf207b-3b29-4e97-c3b8-9582fc9cbff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pre_train(model, optimizer, loops = 10000, batch_size = 300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 422s 42ms/step - loss: 4.4897e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veSorb7Z_PLG",
        "colab_type": "code",
        "outputId": "b090588f-2a20-44d8-b550-11261fbd725d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pre_train(model, optimizer, loops = 10000, batch_size = 300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 427s 43ms/step - loss: 3.0594e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urTf19bSqUNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "version = '0.2.2'\n",
        "game_num = 'pre30000x300'\n",
        "\n",
        "save(fname(version, game_num), model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mlOE_I84O5hD"
      },
      "source": [
        "## Profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Etz9nnawU0i",
        "outputId": "5af83d07-ff64-43fc-fc96-e1bd01df5bbf",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# from torch.optim import SGD\n",
        "# version = '0.2.2'\n",
        "# game_num = '70000'\n",
        "# model = TDConway(config).to(device)\n",
        "# optimizer = SGD(model.parameters(), lr = 0.01)\n",
        "# model = load(version, game_num, model)\n",
        "\n",
        "# # %timeit get_next_move_training(initial_state, model, device)\n",
        "# %timeit training_loop(model, optimizer, 1, device, off_policy = epsilon_greedy)\n",
        "# %prun training_loop(model, optimizer, 1, device, off_policy = epsilon_greedy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-37512377276b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# %timeit get_next_move_training(initial_state, model, device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit training_loop(model, optimizer, 1, device, off_policy = epsilon_greedy)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prun training_loop(model, optimizer, 1, device, off_policy = epsilon_greedy)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'epsilon_greedy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eqLsixqoP3kV"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB5nj1edBoaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "eastern = timezone('US/Eastern')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsYoeCm2q-Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon_greedy = EpsilonGreedy(0.01)\n",
        "model = TDConway(config).to(device)\n",
        "optimizer = AlternatingTDLambda(model.parameters(), 0.01, 0.9)\n",
        "\n",
        "version  = '0.2.2'\n",
        "game_num = 82000\n",
        "\n",
        "load(version, game_num, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92NgliNkT7vm",
        "colab_type": "code",
        "outputId": "160c5d5c-530b-47d2-c00d-bcb55647ea2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "version = '0.2.2'\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "while True: # Until Colab or User disconnects out of boredom\n",
        "  try:\n",
        "    training_loop(model, optimizer, batch_size, device, off_policy = epsilon_greedy, verbose = 1)\n",
        "    game_num += batch_size\n",
        "\n",
        "    save(fname(version, game_num), model)\n",
        "\n",
        "    print(f'Finished {game_num} games at', datetime.now(eastern).strftime('%I:%M%p %Z'))\n",
        "  except KeyboardInterrupt:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 735s 1s/step\n",
            "Finished 70500 games at 06:53AM EDT\n",
            "500/500 [==============================] - 677s 1s/step\n",
            "Finished 71000 games at 07:05AM EDT\n",
            "500/500 [==============================] - 595s 1s/step\n",
            "Finished 71500 games at 07:15AM EDT\n",
            "500/500 [==============================] - 750s 2s/step\n",
            "Finished 72000 games at 07:27AM EDT\n",
            "500/500 [==============================] - 740s 1s/step\n",
            "Finished 72500 games at 07:39AM EDT\n",
            "500/500 [==============================] - 655s 1s/step\n",
            "Finished 73000 games at 07:50AM EDT\n",
            "500/500 [==============================] - 654s 1s/step\n",
            "Finished 73500 games at 08:01AM EDT\n",
            "500/500 [==============================] - 579s 1s/step\n",
            "Finished 74000 games at 08:11AM EDT\n",
            "500/500 [==============================] - 433s 865ms/step\n",
            "Finished 74500 games at 08:18AM EDT\n",
            "500/500 [==============================] - 326s 653ms/step\n",
            "Finished 75000 games at 08:24AM EDT\n",
            "500/500 [==============================] - 328s 656ms/step\n",
            "Finished 75500 games at 08:29AM EDT\n",
            "500/500 [==============================] - 334s 669ms/step\n",
            "Finished 76000 games at 08:35AM EDT\n",
            "500/500 [==============================] - 366s 731ms/step\n",
            "Finished 76500 games at 08:41AM EDT\n",
            "500/500 [==============================] - 361s 721ms/step\n",
            "Finished 77000 games at 08:47AM EDT\n",
            "500/500 [==============================] - 301s 602ms/step\n",
            "Finished 77500 games at 08:52AM EDT\n",
            "500/500 [==============================] - 316s 631ms/step\n",
            "Finished 78000 games at 08:57AM EDT\n",
            "500/500 [==============================] - 321s 642ms/step\n",
            "Finished 78500 games at 09:03AM EDT\n",
            "500/500 [==============================] - 331s 662ms/step\n",
            "Finished 79000 games at 09:08AM EDT\n",
            "500/500 [==============================] - 370s 740ms/step\n",
            "Finished 79500 games at 09:14AM EDT\n",
            "500/500 [==============================] - 498s 995ms/step\n",
            "Finished 80000 games at 09:23AM EDT\n",
            "500/500 [==============================] - 709s 1s/step\n",
            "Finished 80500 games at 09:34AM EDT\n",
            "500/500 [==============================] - 436s 872ms/step\n",
            "Finished 81000 games at 09:42AM EDT\n",
            "500/500 [==============================] - 415s 829ms/step\n",
            "Finished 81500 games at 09:49AM EDT\n",
            "500/500 [==============================] - 367s 734ms/step\n",
            "Finished 82000 games at 09:55AM EDT\n",
            "500/500 [==============================] - 484s 969ms/step\n",
            "Finished 82500 games at 10:03AM EDT\n",
            " 49/500 [=>............................] - ETA: 23:44"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BSf5Sb434Rq",
        "colab_type": "text"
      },
      "source": [
        "nope now it's slow :("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hywC_0PRNKdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Versioning:\n",
        "#  Major versions - major change in approach\n",
        "#  Minor versions - incompatible architecture tweaks\n",
        "#  Build          - retraining or changes in training parameters\n",
        "#  Game number    - number of games trained or pre{E}x{B} where E is the the\n",
        "#                   number of batches and B is the batch size for pre-training\n",
        "# Example: v0.1.2 @400 is the second attempt at training the v0.1 architecture\n",
        "#  and was trained for 400 games\n",
        "\n",
        "# Performance benchmarks.\n",
        "#  GPU benchmarks are on a P100 unless otherwise stated\n",
        "#    per move    : training-relevant\n",
        "#    forward pass: evaluation (arena mode) relevant\n",
        "#  CPU benchmarks are for inference on a fixed set of 300 randomly\n",
        "#    generated boards on an Intel i5 chipset. (deployment-relevant)\n",
        "#  Memory consumption has not been an issue\n",
        "\n",
        "# v0.1: architecture from model_v1. Training: Alternating TD(λ)\n",
        "#  ~60M params (59,943,809)\n",
        "#  GPU: 100–110ms/move with 50-60ms for forward pass\n",
        "#  CPU: 8.1s ± 0.5s \n",
        "#  alpha = 0.01, lambda = 0.9, epsilon = 0.1\n",
        "#\n",
        "#  - v0.1.1 - don't use, bug in training\n",
        "#  - v0.1.2 - Use. available @400. Win rate v RandoTron 51% (😢)\n",
        "\n",
        "# v0.2: architecture from model_v2.\n",
        "#  Training: Alternating TD(λ) WITH pretraining to prefer the ball to the\n",
        "#   right on randomly generated boards\n",
        "#  ~4.4M params (4,381,505)\n",
        "#  GPU: 30-35ms/move with ~12ms for forward pass\n",
        "#  CPU: 1.1s ± 0.02s\n",
        "#\n",
        "# - v0.2.1 - Available @pre10000x300, @400, @1500, @3500\n",
        "#          - Hyperparameters same as v0.1\n",
        "#            Win rate v RandoTron \n",
        "#            - @pre-trained: 75.4% ±1.4% (!?)\n",
        "#            - @400: 49%\n",
        "#            - @1500: 56.9% ±1.8%\n",
        "#            - @3500: 54.8% ±1.7%\n",
        "#            - In further increments of 500 as [4000, 4500, ..., 20500]\n",
        "#            - @10500: 60.3% ±1.6%\n",
        "#            - @17500: 59.5% ±1.2%\n",
        "# - v0.2.2 - Increased pretraining, epsilon = 0.01\n",
        "#          - Available @pre30000x300 (71.2% ± 2.3%)\n",
        "#          - And in increments of 500 [500, 1000, ..., 82000]\n",
        "#          - @17500: 71.5% ±1.1%\n",
        "#          - @82000: 99.8% ±0.1%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB7XLdBFAI1i",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYsHmg68JIkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lib.arena import Player, Battle, RandoTron"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNbNXAIuJLS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Player 1\n",
        "model = TDConway(config).to(device)\n",
        "version  = '0.2.2'\n",
        "game_num = 82000\n",
        "sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt', map_location = device)\n",
        "model.load_state_dict(sd['model'])\n",
        "# optimizer.load_state_dict(sd['optim'])\n",
        "\n",
        "td_conway = Player(model, name = f'TD Conway v{version} @{game_num}')\n",
        "td_conway.eval()\n",
        "randotron = RandoTron()\n",
        "battle    = Battle(td_conway, randotron, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALkfa_V9cjH-",
        "colab_type": "code",
        "outputId": "c07adc0d-b9d7-4fd0-d105-f271296aec2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "battle.play_match(1600, device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600/1600 [==============================] - 142s 89ms/step\n",
            "1600 games were played between TD Conway v0.2.2 @82000 and RandoTron with 0 draws.\n",
            "The winner was TD Conway v0.2.2 @82000 with a 99.8% win rate!\n",
            "TD Conway v0.2.2 @82000 on average won in a game of length 15.4.\n",
            "RandoTron on average won in a game of length 59.7\n",
            "Overall average length of game was 15.471875\n",
            "Total time taken: 2:22 at\n",
            " - 89ms per finished game.\n",
            " - 6ms per move in a finished game\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O0diFCd6M4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Player 1 @3500\n",
        "model = TDConway(config).to(device)\n",
        "version  = '0.2.1'\n",
        "game_num = 3500\n",
        "sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt', map_location = device)\n",
        "model.load_state_dict(sd['model'])\n",
        "td_conway_1 = Player(model, name = f'TD Conway v{version} @{game_num}')\n",
        "td_conway_1.eval()\n",
        "\n",
        "# Player 2 @ 10500\n",
        "model = TDConway(config).to(device)\n",
        "version  = '0.2.1'\n",
        "game_num = 10500\n",
        "sd = torch.load(f'{data_dir}/{fname(version, game_num)}.pt', map_location = device)\n",
        "model.load_state_dict(sd['model'])\n",
        "td_conway_2 = Player(model, name = f'TD Conway v{version} @{game_num}')\n",
        "td_conway_2.eval()\n",
        "\n",
        "battle    = Battle(td_conway_1, td_conway_2, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNwLyUBQ-LU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "battle.play_match(900, device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}