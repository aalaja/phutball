{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "model-training.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY-nqnzUzB5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open this notebook in Colab (if you want to train)\n",
        "# at https://colab.research.google.com/github/rcharan/phutball/blob/rl/pytorch-implementation/model-training.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNflNJ9jxDhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5f272f9b-ef87-4ec4-9c52-a498cc520ba0"
      },
      "source": [
        "# Mount Google Drive at data_dir\n",
        "#  (for data)\n",
        "from google.colab import drive\n",
        "from os.path import join\n",
        "ROOT = '/content/drive'\n",
        "DATA = 'My Drive/phutball'\n",
        "drive.mount(ROOT)\n",
        "data_dir = join(ROOT, DATA)\n",
        "!mkdir \"{data_dir}\"     # in case we haven't created it already   "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/phutball’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRiJoZ6mwrgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c66f7416-f6e1-4ef7-e175-8653de514e03"
      },
      "source": [
        "# Pull in code from github\n",
        "%cd /content\n",
        "github_repo = 'https://github.com/rcharan/phutball'\n",
        "!git clone -b rl {github_repo}\n",
        "%cd /content/phutball"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'phutball'...\n",
            "remote: Enumerating objects: 1374, done.\u001b[K\n",
            "remote: Counting objects: 100% (1374/1374), done.\u001b[K\n",
            "remote: Compressing objects: 100% (755/755), done.\u001b[K\n",
            "remote: Total 1374 (delta 809), reused 1133 (delta 580), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1374/1374), 6.29 MiB | 26.51 MiB/s, done.\n",
            "Resolving deltas: 100% (809/809), done.\n",
            "/content/phutball\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH-tewNy3knY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "079ff28d-9f44-42cf-f799-0ac74316f647"
      },
      "source": [
        "VERSION = \"nightly\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3727  100  3727    0     0  45451      0 --:--:-- --:--:-- --:--:-- 45451\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-nightly ...\n",
            "Uninstalling torch-1.5.0+cu101:\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "  Successfully uninstalled torch-1.5.0+cu101\n",
            "Uninstalling torchvision-0.6.0+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 90.7 MiB/ 90.7 MiB]                                                \n",
            "Operation completed over 1 objects/90.7 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+328dd9e\n",
            "Processing ./torch_xla-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+135a02e\n",
            "Processing ./torchvision-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.6.0a0+328dd9e)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+7aea80c\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (362 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144429 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBXOJlAR5z0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_bytes(num):\n",
        "  for unit in 'BKMGTPEZ':\n",
        "    if num < 1024:\n",
        "        return f'{num:.2f}{unit}iB'\n",
        "    num /= 1024.0\n",
        "  return f'{num:.2f}YB'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbzAupTP6DOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For Memory Management\n",
        "def print_memory_usage():\n",
        "    for i in range(cutorch.device_count()):\n",
        "        print(f'GPU {i}     : ' + format_bytes(torch.cuda.memory_allocated(device=0)))\n",
        "\n",
        "def print_max_memory_usage():\n",
        "    for i in range(cutorch.device_count()):\n",
        "        print(f'GPU {i} Peak: ' + format_bytes(torch.cuda.max_memory_allocated(device=0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jokW_fD56EJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cuda_garbage_collect():\n",
        "  print_memory_usage()\n",
        "  print('Collecting Garbage...',   gc.collect())\n",
        "  torch.cuda.empty_cache()\n",
        "  print_memory_usage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RxX5jLh6LR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Timer:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.start_time = datetime.now()\n",
        "\n",
        "  def elapsed_time(self):\n",
        "    return (datetime.now() - self.start_time)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.pretty_print(self.elapsed_time())\n",
        "\n",
        "  @staticmethod\n",
        "  def pretty_print(timedelta):\n",
        "    total_seconds = timedelta.total_seconds()\n",
        "    multiples = [24, 60, 60, 1]\n",
        "    formats   = [\n",
        "      lambda days  : f'{days} days ',\n",
        "      lambda hours : f'{hours}:',\n",
        "      lambda mins  : f'{mins:02d}:',\n",
        "      lambda secs  : f'{secs:02d}',\n",
        "    ]\n",
        "    force_zeros = False\n",
        "    out = ''\n",
        "    for formatter in formats:\n",
        "      quot          = floor(total_seconds / product(multiples))\n",
        "      total_seconds = total_seconds - quot * product(multiples)\n",
        "      multiples = multiples[1:]\n",
        "      if quot == 0 and not force_zeros:\n",
        "        continue\n",
        "      else:\n",
        "        amt_to_append = formatter(quot)\n",
        "        if not force_zeros and amt_to_append[0] == '0':\n",
        "          amt_to_append = amt_to_append[1:]\n",
        "        out += amt_to_append\n",
        "        force_zeros = True\n",
        "    \n",
        "    if not force_zeros: # Display milliseconds only\n",
        "      out += f'{total_seconds*1000:.0f}ms'\n",
        "    elif timedelta.total_seconds() < 10:\n",
        "      out += f'{total_seconds:.1f}s'[1:]\n",
        "    elif timedelta.total_seconds() < 60:\n",
        "      out += 's'\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_NbjmTg5xAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detect gpu availability\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print('Using GPU')\n",
        "else:\n",
        "  print('Using CPU')\n",
        "  device = torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKYUxLPd4572",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "55ed5ca9-2612-4bd8-9e92-969e007ee32b"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/14)\u001b[K\rremote: Counting objects:  14% (2/14)\u001b[K\rremote: Counting objects:  21% (3/14)\u001b[K\rremote: Counting objects:  28% (4/14)\u001b[K\rremote: Counting objects:  35% (5/14)\u001b[K\rremote: Counting objects:  42% (6/14)\u001b[K\rremote: Counting objects:  50% (7/14)\u001b[K\rremote: Counting objects:  57% (8/14)\u001b[K\rremote: Counting objects:  64% (9/14)\u001b[K\rremote: Counting objects:  71% (10/14)\u001b[K\rremote: Counting objects:  78% (11/14)\u001b[K\rremote: Counting objects:  85% (12/14)\u001b[K\rremote: Counting objects:  92% (13/14)\u001b[K\rremote: Counting objects: 100% (14/14)\u001b[K\rremote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 8 (delta 6), reused 8 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects:  12% (1/8)   \rUnpacking objects:  25% (2/8)   \rUnpacking objects:  37% (3/8)   \rUnpacking objects:  50% (4/8)   \rUnpacking objects:  62% (5/8)   \rUnpacking objects:  75% (6/8)   \rUnpacking objects:  87% (7/8)   \rUnpacking objects: 100% (8/8)   \rUnpacking objects: 100% (8/8), done.\n",
            "From https://github.com/rcharan/phutball\n",
            "   d4ed70a..b5c1be3  rl         -> origin/rl\n",
            "Updating d4ed70a..b5c1be3\n",
            "Fast-forward\n",
            " pytorch-implementation/lib/moves.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZrjYR5p355l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8jgFwuo4GGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = xm.xla_device()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbaorYhzwUze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZwtWnrR01MN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/phutball/pytorch-implementation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lh-L2-pwUzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lib.model_v1 import TDConway\n",
        "from lib.moves import create_placement_getter, get_jumps\n",
        "from lib.utilities import config\n",
        "\n",
        "from lib.testing_utilities import create_state, visualize_state, boards\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.ioff()\n",
        "\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import gc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upeN3_XK3GsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import psutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBpw7Ul8wUzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# device = torch.device('cpu')\n",
        "get_placements = create_placement_getter(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKTjg7fcwUzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TDConway(config).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk_MuwokwUzz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2d1aeba1-6790-4f4c-bf7e-e8a6cca0c9d7"
      },
      "source": [
        "initial_state = create_state('H10').to(device)\n",
        "visualize_state(initial_state.cpu())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DwZFYQAwUz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "curr_state = initial_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl9_Q1WNwUz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "MAX_JUMPS = 300\n",
        "from lib.moves import END_LOC, COL, CHAIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF7BrTwZwUz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkzXSlsbwU0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlternatingTDLambda(Optimizer):\n",
        "  '''Implements tracing and updates for the TD(λ) algorithm.\n",
        "  \n",
        "  For details see Sutton and Barto, Reinforcement Learning 2ed,\n",
        "  Chaper 12 Section 2.\n",
        "  \n",
        "  Modifications:\n",
        "    (1) the algorithm is modified to compute traces\n",
        "        one step early (when the graph is available). Hence, trace must be\n",
        "        initialized with update_trace before calling step.\n",
        "        \n",
        "    (2) Because the board switches sides each turn, eligibility trace updates\n",
        "        must be of the form z_t+1 <-  -λz_t + 𝝯v\n",
        "  \n",
        "  You may find the following greeks a helpful reference:\n",
        "  alpha : Learning Rate\n",
        "  lambda: Exponential Decay parameter for the eligibility trace\n",
        "          (which is essentially momentum but with different\n",
        "           interpertation and is occasionally zeroed out).\n",
        "  delta : Temporal difference (TD) i.e. the difference between the estimated\n",
        "          value of a step and the realized value upon the best move (based\n",
        "          on further estimation of course).\n",
        "  '''\n",
        "  def __init__(self, parameters, alpha, lamda):\n",
        "    self.alpha = alpha\n",
        "    self.lamda = lamda # Note alternate spelling (I didn't make it up!)\n",
        "    defaults   = dict(alpha = alpha, lamda = lamda)\n",
        "\n",
        "    super(TDLambda, self).__init__(parameters, defaults)\n",
        "    \n",
        "  @torch.no_grad()\n",
        "  def step(self, delta, update_trace = True):\n",
        "    '''Performs a single optimization step updating the trace *afterwards*\n",
        "    \n",
        "    update_trace must be called before first step to initialize the trace.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    \n",
        "    delta: Difference between estimated value of move at time t and realized\n",
        "           value after moving and going to time t+1\n",
        "    '''\n",
        "    \n",
        "    for group in self.param_groups:\n",
        "      alpha = group['alpha']\n",
        "      \n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        \n",
        "        state = self.state[p]\n",
        "        \n",
        "        if len(state) == 0 or 'trace' not in state:\n",
        "          raise RuntimeError('Traces must be initialized before calling step')\n",
        "          \n",
        "        trace = state['trace']\n",
        "        \n",
        "        p.add_(alpha * delta * trace) # Note gradient *ascent* in reinforcement learning\n",
        "    \n",
        "    if update_trace:\n",
        "      self.update_trace()\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def update_trace(self):\n",
        "    '''Updates the trace based on the gradients.\n",
        "    \n",
        "    This also is the only way to initialize the traces.\n",
        "    It must be called after evaluating the starting position\n",
        "    and backprop at the beginning of the game.\n",
        "    '''\n",
        "    for group in self.param_groups:\n",
        "      lamda = group['lamda']\n",
        "      \n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        \n",
        "        state = self.state[p]\n",
        "        \n",
        "        # Initialize to zero if necessary\n",
        "        if len(state) == 0 or 'trace' not in state:\n",
        "          state['trace'] = torch.zeros_like(p)\n",
        "          \n",
        "        trace = state['trace']\n",
        "        trace.mul_(-lamda).add_(p.grad)\n",
        "      \n",
        "  @torch.no_grad()\n",
        "  def zero_trace(self):\n",
        "    for group in self.param_groups:\n",
        "      for p in group['params']:\n",
        "        state = self.state['p']\n",
        "        if 'trace' not in state:\n",
        "          continue\n",
        "          \n",
        "        trace = state['trace']\n",
        "        trace.zero_()\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4L9vL3EwU0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import Progbar as ProgressBar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1CAfi-4wU0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop(optimizer, num_games, off_policy = lambda _ : None):\n",
        "  \n",
        "  initial_state = create_state('H10').to(device)\n",
        "  for i in range(num_games):\n",
        "    print(f'\\nPlaying game {i+1} of {num_games}:')\n",
        "    game_loop(initial_state, model, optimizer, off_policy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EptuWzBSwU0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def restart(optimizer, score):\n",
        "  optimizer.zero_trace()\n",
        "  score.backwards()\n",
        "  optimizer.update_trace()\n",
        "  optimizer.zero_grad()\n",
        "  return score.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62GkFibrwU0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def game_loop(initial_state, model, optimizer, off_policy):\n",
        "  '''Training loop that plays one game'''\n",
        "  # Just in case\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  # Initialization\n",
        "  state    = initial_state\n",
        "  score, _ = model(state.unsqueeze(0))\n",
        "  v_t      = restart(optimizer, score)\n",
        "  \n",
        "  # Progress Bar\n",
        "  bar      = ProgressBar(284)\n",
        "  move_num = 1\n",
        "  \n",
        "  while True:\n",
        "    # Determine the next move\n",
        "    game_over, moved_off_policy, new_state, score = \\\n",
        "      get_next_move_training(curr_state, off_policy = off_policy)\n",
        "    \n",
        "    if game_over:      \n",
        "      delta = 1 - v_t\n",
        "      optimizer.step(delta, update_trace = False)\n",
        "      \n",
        "      # Terminate the progress bar\n",
        "      bar.target = move_num\n",
        "      bar.update(move_num)\n",
        "\n",
        "      break\n",
        "    \n",
        "    elif moved_off_policy:\n",
        "      # Equivalent to starting a new game\n",
        "      v_t = restart(optimizer, score)\n",
        "      \n",
        "    else:\n",
        "      score.backwards()\n",
        "      delta = (1 - score) - v_t\n",
        "      optimizer.step(delta)\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      v_t   = score.item()\n",
        "      state = new_state\n",
        "      \n",
        "    # Progress bar\n",
        "    move_num += 1\n",
        "    if move_num >= bar.target * 0.9:\n",
        "      bar.target += bar.target // 10 + 1\n",
        "    \n",
        "    bar.update(move_num)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_Kl9lNTwU0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_next_move_training(curr_state, off_policy = lambda _ : None):\n",
        "  '''Get the next move for the bot\n",
        "  \n",
        "  Gets the next move for the bot with computations and\n",
        "  return value suitable for training only\n",
        "  (i.e. gradients are taken)\n",
        "  \n",
        "  If off_policy is not None, the off_policy move is\n",
        "  selected instead.\n",
        "  \n",
        "  Gradients with respect to the value-function applied\n",
        "  at the best move are accumlated and availabe to the caller\n",
        "  \n",
        "  Inputs\n",
        "  ------\n",
        "  \n",
        "  curr_state: binary tensor of shape (channels, rows, cols)\n",
        "              reprenting the game state\n",
        "              \n",
        "  off_policy: callable with signature\n",
        "              off_policy(num_available_moves: int) returning\n",
        "              either None or the index of the move desired.\n",
        "              If the return value is not None AND the bot \n",
        "              cannot otherwise win on that move, then that\n",
        "              move is made.\n",
        "              \n",
        "  Outputs\n",
        "  -------\n",
        "  game_over  : boolean. Whether the bot can (and does) win\n",
        "             on this move. The bot *always* plays a\n",
        "             win-in-one move when it is available, regardless\n",
        "             of the off-policy argument.\n",
        "             \n",
        "  off_policy : boolean. Whether an off-policy move was made.\n",
        "             OR: value is None if game is over\n",
        "  \n",
        "  new_state  : a binary tensor of same shape as curr_input\n",
        "             representing the new state of the game after\n",
        "             the bot moves AND the board is flipped around\n",
        "             to present it from opponents view. OR: value\n",
        "             is None if game is over.\n",
        "               \n",
        "  value      : value of the value-function applied to new_state.\n",
        "             OR: value is None if the game is over.\n",
        "  '''\n",
        "  # Compute the placements\n",
        "  placements = get_placements(curr_state)\n",
        "\n",
        "  # Compute the jumps\n",
        "  jumps = get_jumps(curr_state, MAX_JUMPS)\n",
        "\n",
        "  # Deal with special cases/win condition for the jump\n",
        "  \n",
        "  # No jumps to worry about\n",
        "  if len(jumps) == 0:\n",
        "    moves = placements\n",
        "  \n",
        "  # Win condition\n",
        "  elif (\n",
        "    len(jumps) == 1 and\n",
        "    jumps[0][CHAIN][END_LOC][COL] in [config.cols, config.cols-1]):\n",
        "    return True, None, None, None # The game is over!\n",
        "  \n",
        "  # Regular jump evaluation\n",
        "  else:\n",
        "    # Retain only the final state\n",
        "    jumps = [jump_data[0] for jump_data in jumps]\n",
        "    jumps = torch.tensor(jumps, dtype = torch.bool)\n",
        "    moves = torch.cat([placements, jumps])\n",
        "    \n",
        "  # Turn the board around to represent the opponent's view\n",
        "  moves = torch.flip(moves, [-1])\n",
        "  \n",
        "  # Either make an off policy move, or evaluate the value-function\n",
        "  #  to determine the policy\n",
        "  if off_policy(moves.shape[0]) is not None:\n",
        "    move     = moves[move].unsqueeze()\n",
        "    score, _ = model(move)\n",
        "    return False, True, move, score\n",
        "  \n",
        "  # Batch the moves\n",
        "  batches = torch.split(moves, BATCH_SIZE)\n",
        "  \n",
        "  # We only need to differentiate the best score\n",
        "  #  track which one that is.\n",
        "  best_score = None\n",
        "  best_index = None\n",
        "  curr_index = 0\n",
        "\n",
        "  process = psutil.Process(os.getpid())\n",
        "  # print(f'{process.memory_info().rss:,d}')\n",
        "  \n",
        "  timer = Timer()\n",
        "  for batch in batches:\n",
        "\n",
        "    \n",
        "    # Run the model\n",
        "    score, index = model(batch)\n",
        "\n",
        "    # Update running tally of best score\n",
        "    #  Old best scores should have their graphs\n",
        "    #  destroyed\n",
        "\n",
        "    if best_score is None or score > best_score:\n",
        "      best_score = score\n",
        "      best_index = curr_index + index\n",
        "\n",
        "    # Keep track of how many indices we've traversed to \n",
        "    #  get best_index correct\n",
        "    curr_index += batch.shape[0]\n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    print(timer)\n",
        "    # print(f'{process.memory_info().rss:,d}')\n",
        "    \n",
        "  # Return\n",
        "  return False, False, moves[best_index], best_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Etz9nnawU0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "646b3347-ee2f-4cc5-a2d8-6bc1680dc8d8"
      },
      "source": [
        "get_next_move_training(initial_state)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108ms\n",
            "3.7s\n",
            "17s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-68b887015a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_next_move_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-10>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    396\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_default_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_safe_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_baseclass_reprs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# A user-provided repr. Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:.0f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvde96eR6aRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "from math import floor\n",
        "from lib.utilities import product"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQACdXqC5CQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}